#!/usr/bin/env python3
"""
DEMO TH·ª∞C T·∫æ - Hu·∫•n luy·ªán CNN tr√™n MNIST
Ch∆∞∆°ng 4: X√¢y d·ª±ng k·ªãch b·∫£n demo tr√™n h·ªá th·ªëng AI gi·∫£ ƒë·ªãnh
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import os
from pathlib import Path

# ============== B∆Ø·ªöC 1: ƒê·ªãnh nghƒ©a CNN Architecture ==============
class SimpleCNN(nn.Module):
    """CNN ƒë∆°n gi·∫£n cho ph√¢n lo·∫°i MNIST"""
    
    def __init__(self):
        super(SimpleCNN, self).__init__()
        # Conv Layer 1
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(2, 2)
        
        # Conv Layer 2
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(2, 2)
        
        # Fully Connected Layers
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(128, 10)
    
    def forward(self, x):
        x = self.pool1(self.relu1(self.conv1(x)))
        x = self.pool2(self.relu2(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = self.relu3(self.fc1(x))
        x = self.fc2(x)
        return x

def train_model(num_epochs=5, batch_size=128, learning_rate=0.001):
    """
    Hu·∫•n luy·ªán CNN tr√™n MNIST
    
    Args:
        num_epochs: S·ªë epoch hu·∫•n luy·ªán
        batch_size: K√≠ch th∆∞·ªõc batch
        learning_rate: Learning rate
    
    Returns:
        model: M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
        accuracy: ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test
    """
    
    print("\n" + "="*70)
    print("HU·∫§N LUY·ªÜN M√î H√åNH CNN TR√äN MNIST")
    print("="*70)
    
    # ============== B∆Ø·ªöC 2: T·∫£i v√† chu·∫©n b·ªã d·ªØ li·ªáu ==============
    print("\n[*] ƒêang t·∫£i b·ªô d·ªØ li·ªáu MNIST...")
    
    # T·∫°o th∆∞ m·ª•c data n·∫øu ch∆∞a c√≥
    data_dir = Path('./data')
    data_dir.mkdir(exist_ok=True)
    
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    try:
        train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
        test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
    except Exception as e:
        print(f"[!] L·ªói khi t·∫£i MNIST: {e}")
        print("[!] Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet ho·∫∑c t·∫£i th·ªß c√¥ng")
        return None, 0
    
    print(f"[+] ƒê√£ t·∫£i: {len(train_dataset)} m·∫´u hu·∫•n luy·ªán, {len(test_dataset)} m·∫´u test")
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    # ============== B∆Ø·ªöC 3: Kh·ªüi t·∫°o m√¥ h√¨nh ==============
    # S·ª≠ d·ª•ng GPU (CUDA) l√†m m·∫∑c ƒë·ªãnh, fallback sang CPU n·∫øu kh√¥ng c√≥
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"\n[*] Thi·∫øt b·ªã: GPU (CUDA)")
        print(f"[+] GPU: {torch.cuda.get_device_name(0)}")
        print(f"[+] CUDA Version: {torch.version.cuda}")
        print(f"[+] GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    else:
        device = torch.device("cpu")
        print(f"\n[*] Thi·∫øt b·ªã: CPU")
        print("[!] GPU kh√¥ng kh·∫£ d·ª•ng, ƒëang s·ª≠ d·ª•ng CPU (ch·∫≠m h∆°n)")
        print("[üí°] ƒê·ªÉ s·ª≠ d·ª•ng GPU, c√†i PyTorch v·ªõi CUDA:")
        print("    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124")
    
    model = SimpleCNN().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    # In th√¥ng tin m√¥ h√¨nh
    total_params = sum(p.numel() for p in model.parameters())
    print(f"[+] T·ªïng s·ªë tham s·ªë: {total_params:,}")
    
    # ============== B∆Ø·ªöC 4: Hu·∫•n luy·ªán ==============
    print(f"\n[*] B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán ({num_epochs} epochs)...")
    print("-" * 70)
    
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)
            
            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            # Statistics
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            # In progress
            if (batch_idx + 1) % 100 == 0:
                print(f"  Epoch [{epoch+1}/{num_epochs}], "
                      f"Batch [{batch_idx+1}/{len(train_loader)}], "
                      f"Loss: {loss.item():.4f}")
        
        # T√≠nh metrics cho epoch
        avg_loss = total_loss / len(train_loader)
        train_acc = 100 * correct / total
        
        print(f"\nEpoch [{epoch+1}/{num_epochs}] ho√†n th√†nh:")
        print(f"  ‚îú‚îÄ Loss: {avg_loss:.4f}")
        print(f"  ‚îî‚îÄ Train Accuracy: {train_acc:.2f}%")
        print("-" * 70)
    
    # ============== B∆Ø·ªöC 5: ƒê√°nh gi√° tr√™n t·∫≠p test ==============
    print("\n[*] ƒê√°nh gi√° tr√™n t·∫≠p test...")
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    accuracy_clean = 100 * correct / total
    print(f"\n[+] ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test (s·∫°ch): {accuracy_clean:.2f}%")
    
    # ============== B∆Ø·ªöC 6: L∆∞u m√¥ h√¨nh ==============
    model_path = 'mnist_cnn_model.pth'
    torch.save({
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'accuracy': accuracy_clean,
        'epoch': num_epochs
    }, model_path)
    
    print(f"[+] M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {model_path}")
    print("="*70 + "\n")
    
    return model, accuracy_clean

def main():
    """H√†m main"""
    try:
        model, accuracy = train_model(num_epochs=5)
        
        if model is not None:
            print("\n‚úÖ Hu·∫•n luy·ªán th√†nh c√¥ng!")
            print(f"üìä ƒê·ªô ch√≠nh x√°c: {accuracy:.2f}%")
            print(f"üíæ Model saved: mnist_cnn_model.pth")
            print("\nüìù B∆∞·ªõc ti·∫øp theo:")
            print("   python demo_evasion_attack.py")
        else:
            print("\n‚ùå Hu·∫•n luy·ªán th·∫•t b·∫°i!")
            return 1
        
        return 0
        
    except KeyboardInterrupt:
        print("\n\n[!] ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
        return 1
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    import sys
    sys.exit(main())

