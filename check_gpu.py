#!/usr/bin/env python3
"""
Script ki·ªÉm tra GPU v√† h∆∞·ªõng d·∫´n c√†i ƒë·∫∑t PyTorch v·ªõi CUDA 12.4
"""

def check_gpu():
    """Ki·ªÉm tra GPU v√† in th√¥ng tin chi ti·∫øt"""
    
    print("\n" + "="*70)
    print("KI·ªÇM TRA GPU V√Ä CUDA")
    print("="*70)
    
    try:
        import torch
        print("\n[‚úì] PyTorch ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        print(f"[+] PyTorch version: {torch.__version__}")
        
        # Ki·ªÉm tra CUDA
        if torch.cuda.is_available():
            print("\n[‚úì] GPU (CUDA) KH·∫¢ D·ª§NG!")
            print(f"[+] CUDA version: {torch.version.cuda}")
            print(f"[+] cuDNN version: {torch.backends.cudnn.version()}")
            
            # Th√¥ng tin GPU
            print(f"\n[üìä] Th√¥ng tin GPU:")
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"\n  GPU {i}: {torch.cuda.get_device_name(i)}")
                print(f"    ‚îú‚îÄ Memory: {props.total_memory / 1e9:.2f} GB")
                print(f"    ‚îú‚îÄ Compute Capability: {props.major}.{props.minor}")
                print(f"    ‚îî‚îÄ Multi Processors: {props.multi_processor_count}")
            
            # Test GPU
            print("\n[üîß] Test GPU performance...")
            try:
                x = torch.randn(1000, 1000).cuda()
                y = torch.randn(1000, 1000).cuda()
                import time
                start = time.time()
                z = torch.matmul(x, y)
                torch.cuda.synchronize()
                elapsed = time.time() - start
                print(f"[+] Matrix multiplication (1000x1000): {elapsed*1000:.2f}ms")
                print("[‚úì] GPU ho·∫°t ƒë·ªông t·ªët!")
            except Exception as e:
                print(f"[!] L·ªói khi test GPU: {e}")
            
            print("\n" + "="*70)
            print("‚úÖ SYSTEM READY - C√≥ th·ªÉ s·ª≠ d·ª•ng GPU!")
            print("="*70)
            
        else:
            print("\n[!] GPU KH√îNG KH·∫¢ D·ª§NG")
            print("[!] PyTorch ƒëang ch·∫°y tr√™n CPU")
            
            # Ki·ªÉm tra l√Ω do
            print("\n[üîç] Nguy√™n nh√¢n c√≥ th·ªÉ:")
            print("  1. PyTorch ƒë∆∞·ª£c c√†i v·ªõi CPU version")
            print("  2. Driver NVIDIA ch∆∞a c√†i ho·∫∑c qu√° c≈©")
            print("  3. CUDA toolkit ch∆∞a c√†i ƒë·∫∑t")
            print("  4. M√°y kh√¥ng c√≥ GPU NVIDIA")
            
            # H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t
            print("\n[üí°] C√°ch kh·∫Øc ph·ª•c:")
            print("\n  B∆∞·ªõc 1: G·ª° PyTorch hi·ªán t·∫°i")
            print("    pip uninstall torch torchvision")
            
            print("\n  B∆∞·ªõc 2: C√†i PyTorch v·ªõi CUDA 12.4")
            print("    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124")
            
            print("\n  B∆∞·ªõc 3: Ki·ªÉm tra l·∫°i")
            print("    python check_gpu.py")
            
            print("\n" + "="*70)
            print("‚ö†Ô∏è  ƒêANG D√ôNG CPU - Demo s·∫Ω ch·∫°y ch·∫≠m h∆°n")
            print("="*70)
            
    except ImportError:
        print("\n[‚úó] PyTorch ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t!")
        print("\n[üìù] H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t:")
        
        print("\n1Ô∏è‚É£  C√ÄI V·ªöI GPU (CUDA 12.4) - Khuy·∫øn ngh·ªã:")
        print("    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124")
        
        print("\n2Ô∏è‚É£  C√ÄI V·ªöI CPU (kh√¥ng c·∫ßn GPU):")
        print("    pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu")
        
        print("\n3Ô∏è‚É£  Sau khi c√†i, ch·∫°y l·∫°i:")
        print("    python check_gpu.py")
        
        print("\n" + "="*70)
    
    except Exception as e:
        print(f"\n[‚úó] L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
        import traceback
        traceback.print_exc()

def check_nvidia_driver():
    """Ki·ªÉm tra NVIDIA driver"""
    import subprocess
    
    print("\n" + "="*70)
    print("KI·ªÇM TRA NVIDIA DRIVER")
    print("="*70)
    
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            print("\n[‚úì] NVIDIA Driver ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
            print("\n" + result.stdout)
        else:
            print("\n[‚úó] nvidia-smi kh√¥ng ch·∫°y ƒë∆∞·ª£c")
            print("[!] C√≥ th·ªÉ driver ch∆∞a c√†i ho·∫∑c kh√¥ng ƒë√∫ng")
    except FileNotFoundError:
        print("\n[‚úó] nvidia-smi kh√¥ng t√¨m th·∫•y")
        print("[!] NVIDIA Driver ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        print("\n[üí°] T·∫£i driver t·∫°i: https://www.nvidia.com/Download/index.aspx")
    except subprocess.TimeoutExpired:
        print("\n[!] nvidia-smi timeout")
    except Exception as e:
        print(f"\n[!] L·ªói: {e}")

def main():
    """Main function"""
    
    print("\n" + "="*70)
    print("üîç C√îNG C·ª§ KI·ªÇM TRA GPU V√Ä CUDA CHO DEMO TH·ª∞C T·∫æ")
    print("="*70)
    
    # Check NVIDIA driver
    check_nvidia_driver()
    
    # Check GPU
    check_gpu()
    
    # T√≥m t·∫Øt
    print("\n" + "="*70)
    print("üìö T√ÄI LI·ªÜU THAM KH·∫¢O")
    print("="*70)
    print("  ‚Ä¢ PyTorch installation: https://pytorch.org/get-started/locally/")
    print("  ‚Ä¢ NVIDIA drivers: https://www.nvidia.com/Download/index.aspx")
    print("  ‚Ä¢ CUDA toolkit: https://developer.nvidia.com/cuda-downloads")
    print("="*70 + "\n")

if __name__ == "__main__":
    main()

